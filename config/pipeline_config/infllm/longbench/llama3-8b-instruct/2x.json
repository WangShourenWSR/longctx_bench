{
    "pipeline_params": {
        "method": "inf-llm",
        "model_name": "meta-llama/Meta-Llama-3-8B-Instruct",
        "tokenizer_name": "meta-llama/Meta-Llama-3-8B-Instruct",
        "block_size": 128,
        "fattn": true,
        "truncation_mode": null,
        "batch_size": 1,
        "out_of_max_len_allowed": true,
        "topk": 16,
        "repr_topk": 4,
        "max_cached_block": 32,
        "exc_block_size": 512,
        "base": 500000,
        "distance_scale": 1.0,
        "model_max_len": 7500,
        "chunk_size": 8192,
        "chat_template": "llama3",
        "rope_theta_factor": 1.0,
        "compression_ratio": 0.5,
        "init_ratio": 0.021,
        "local_ratio": 0.655,
        "context_ratio": 0.324
    }
}
